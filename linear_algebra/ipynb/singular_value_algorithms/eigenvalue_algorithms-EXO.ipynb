{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rayleigh quotient\n",
    "\n",
    "+ $M$: Hermitian matrix \n",
    "+ $x$: nonzero vector \n",
    "\n",
    "+ __Rayleigh quotient__: $R(M,x)={x^{*}Mx \\over x^{*}x}$\n",
    "\n",
    "If $x$ is an eigenvector of $A$ then $R(M,x)$ is its eigenvalue.\n",
    "Otherwise, $R(M,x)$ is the closest scalar to an eigenvalue (in least squares): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__:\n",
    "\n",
    "Which is the value $\\alpha$ that minimizes $||Ax - \\alpha x||_2^2$?\n",
    "\n",
    "__hint__: Compute the derivative of $||Ax - \\alpha x||_2^2$ w.r.t. $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__:\n",
    "    \n",
    "+ Set numpy's random generator to 0 (use the `np.random.seed` function)\n",
    "+ Generate $A$, a $2 \\times 2$ random matrix (use `np.random.randn`)\n",
    "+ Compute $M = A^* A$. Is this matrix Hermitian?\n",
    "+ Compute its eigenvalues and eigenvectors (use `np.linalg.eig`)\n",
    "+ Choose one of the eigenvectors and compute its Rayleigh quotient\n",
    "+ Write a function that compute the Rayleigh quotient of a vector, w.r.t. a matrix, both sent as parameters\n",
    "+ Generate 1000 random vectors $\\sim \\mathcal{N}(\\mu = 0,\\sigma = 10)$\n",
    "+ For each vector compute its Rayleigh quotient, w.r.t. $M$\n",
    "+ Plot the histogram of the resulting Rayleigh quotients (use `matplotlib.pyplot.hist`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power iteration\n",
    "A well known method to compute eigenvalues is the power iteration method (also known as the Von Mises iteration).\n",
    "\n",
    "This method takes $A$ a diagonalizable matrix as an input, and it outputs its greatest eigenvalue $\\lambda$ (in absolute value), and its corresponding eigenvector $v$ (i.e., $Av=\\lambda v$).\n",
    "\n",
    "__Power iteration__($A$):\n",
    "+ __initialization__: create $b$ a random vector s.t. $||b||_2 = 1$ \n",
    "+ __Repeat__:\n",
    "    + $w \\leftarrow Ab$\n",
    "    + $b \\leftarrow w/||w||$\n",
    "    + $\\lambda = b^T A b$\n",
    "    \n",
    "This method does not converge if:\n",
    "+ The initial vector $b$ is orthogonal with the eigenvector of $\\lambda$\n",
    "+ The eigenvalue is not unique\n",
    "\n",
    "__Exercise 3__ How does this method work?\n",
    "+ Write $b^{(k)}$ ($b$ at iteration $k$) as a function of $b^{(0)}$ ($b$ at iteration 0) and $A$\n",
    "+ Let us assume that the initial vector is s.t.:\n",
    "$b^{0}=c_{1}v_{1}+c_{2}v_{2}+\\cdots +c_{m}v_{m}$, with $v_i$ the $i$-th eigenvector.\n",
    "+ Decompose $A^k b^{(0)}$ according to the previous equation.\n",
    "+ Factorize by $\\lambda_1$, i.e., the largest eigenvalue.\n",
    "+ When $k$ is large to which value does the previous expression converge?\n",
    "\n",
    "__Exercise 4__ \n",
    "+ Write the Power iteration method\n",
    "+ In order to analyze the algorithm compute:\n",
    "    + The eigenvalues and eigenvectors using `np.linalg.eig`\n",
    "    + Compute the difference between the two largest eigenvalues\n",
    "    + At each iteration compute the difference between the largest eigenvalues output by `np.linalg.eig`, and the current value estimated by the power iteration method.\n",
    "+ For different random matrices $M$ generated as in the previous exercise:\n",
    "    + Run 10 iterations of the power iteration method\n",
    "    + Record and plot the evolution of the error\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse iteration method\n",
    "+ $A$: square matrix, $\\forall i, \\;\\lambda_i$ are eigenvalues of $A$\n",
    "+ Let $\\mu \\in \\mathbb{R}$ s.t. $\\mu \\neq \\lambda_i$\n",
    "\n",
    "Matrix $(A − \\mu I)^{−1}$ and $A$ have the same eigenvectors, \n",
    "and the eigenvalues of $(A − \\mu I)^{−1}$ are $(\\lambda - \\mu)^{-1}$\n",
    "\n",
    "__Exercise 5__: Prove the previous statement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mu$ is close to the eigenvalue $\\lambda_j$ then $(\\lambda_j - \\mu \\mathbf{I})^{-1}$ is a larger eigenvalue than $(\\lambda_i - \\mu \\mathbf{I})^{-1}, \\; \\forall j \\neq i$. \n",
    "\n",
    "The power iteration method applied to $(\\lambda_i - \\mu \\mathbf{I})^{-1}$ converges quickly.\n",
    "\n",
    "__Inverse Iteration Algorithm__ ($A$, $\\mu$):\n",
    "+ __Initialization__: Generate $v$ a random vector with norm 1\n",
    "+ __Repeat__:\n",
    "    + $w \\leftarrow (A-\\mu I)^{-1}v$\n",
    "    + $v \\leftarrow w/||w||$\n",
    "    + $\\lambda \\leftarrow v^TAv$ \n",
    "    \n",
    "__Exercise 6__: \n",
    "+ Program the inverse iteration algorithm\n",
    "+ Generate a random matrix $M$ like in the previous exercises\n",
    "+ Test the algorithm setting $\\mu = 10$ and iterating for 100 steps, and compare to the output of the `np.linalg.eig` function.\n",
    "+ For 100 random values of $\\mu ~\\mathcal{N}(0,\\sigma=10)$, compute an eigenvalue with the inverse iteration algorithm.\n",
    "+ Print the eigenvalues found with 2 decimals precision (use the `np.round` function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration of Rayleigh quotient\n",
    "Instead of using a random value $\\mu$ as initial guess, we can use the Rayleigh quotient instead.\n",
    "\n",
    "Moreover updating $\\mu$ at each iteration allows a faster convergence.\n",
    "\n",
    "These ideas give birth to the Rayleigh quotient iteration method\n",
    "\n",
    "__Rayleigh quotient iteration__($A$):\n",
    "\n",
    "+ __Initialization__: Generate $v$ a random vector with norm 1\n",
    "+ $\\lambda \\leftarrow v^T A v$ (Rayleigh quotient)\n",
    "+ __Repeat__:\n",
    "    + $w = (A-\\lambda)^{-1}v$\n",
    "    + $v = w/||w||$\n",
    "    + $\\lambda = v^T A v$\n",
    "    \n",
    "__Exercise 7__: \n",
    "+ Program the Rayleigh quotient iteration algorithm\n",
    "+ Generate a random matrix $M$ like in the previous exercises\n",
    "+ Test the algorithm, and compare to the output of the `np.linalg.eig` function.\n",
    "+ Compute 100 eigenvalues with the inverse iteration algorithm.\n",
    "+ Print the eigenvalues found with 2 decimals precision (use the `np.round` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schur factorization\n",
    "__Goal__: Factorize $A$ in order to reveal the eigenvalues.\n",
    "\n",
    "$$A = Q T Q^*$$\n",
    "\n",
    "+ $Q$: unitary matrix\n",
    "+ $T$: Upper triangular matrix\n",
    "+ $T$ and $A$ are similar matrices, so they have the same eigenvalues\n",
    "\n",
    "__Theorem__: Every square matrix has a Schur decomposition\n",
    "\n",
    "__Method__: This factorization is computed iteratively using the $QR$ factorization\n",
    "\n",
    "__Schur factorization__(A):\n",
    "+ Let $A_0 = A$\n",
    "+ __Repeat__ for k=0 to $NbIterations$:\n",
    "    + Compute the factorization $A_k = Q_k R_k$\n",
    "    + Define $A_{k+1} = R_k Q_k = Q_k^* A_k Q_k$\n",
    "    \n",
    "    \n",
    "__Exercise 8__:\n",
    "+ Program the Schur factorization algorithm \n",
    "+ Generate a matrix $M$ like in the previous exercises/.\n",
    "+ Compute the matrix $T$ and compare the diagonal of $T$ with the eigenvalues computed with the `np.linalg.eig` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
